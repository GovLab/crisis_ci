
Hi, I'm Peter Bragge from the Monash Sustainable Development Institute at Monash University in Melbourne, Australia.
In this course, I'm going to present how you can mobilize evidence and knowledge in only three days in crisis situations.

Why I think collective intelligence matters in a crisis is the same reason that I do a lot of review work. When you get a lot of knowledge together, you have a lot more power to influence change in positive ways. 
And so, when we bring our minds together, it's a little bit like bringing research together in a research review ,which is what I specialize in. 
So, I'm going to talk about what you can do in only three days in a crisis situation where a government or another stakeholder wants to rapidly learn about a particular topic. 
Obviously a very relevant time frame right now, and governments all around the world are really trying to rapidly assemble information. The same from Lee Jong-wook from the World Health Organization really summarizes the value of packaging knowledge and putting it in front of decision-makers. 
"Action without knowledge is wasted effort and knowledge without action is a wasted resource," and everyone I show this slide to agrees with that statement. But it's surprising how much action does still happen without knowledge and how much knowledge is out there that is not used appropriately.

There are four key principles to mobilizing evidence in a very short timeframe. 
The first is to get the question right. The second is to look for review-level research evidence. The third is to make sure that you understand the quality of the evidence that you have. And the fourth is to mobilize other sources of knowledge. 
I'm going to spend a couple of minutes talking about these four general principles.
A lot of people would say if you've only got three days, can you afford to spend a lot of time getting the question right? The truth is you don't have time to answer the wrong question. 
You have to invest time in understanding the questions that need to be answered, making sure that you and your government or other partner who is commissioning the review understand what is feasible in three days, and crucially, working out how the information needs to be presented. 
So do they want tables, do they want text, do they want diagrams? You don't want to be spending a lot of time going back and forth asking about these sort of things when the deadline is approaching. 

So make sure you get the question right. Fortunately, there's a tool that was recently developed by a group of the University of Sheffield called the STARR Decision Tool, and you can see a link there or you can search for STARR Decision Tool. 
The STARR Decision Tool stands for SelecTing Approaches for Rapid Reviews and it steps you and the commissioner of your review through the key questions that need to be addressed to make sure that you reach a shared understanding of the review that you're doing. 
So it's really important even when you've got a short amount of time to get the question right. The second principle is to look for review-level evidence. It's quicker and what you find is much more reliable than what's on the open Internet. 
Most people, when they're faced with a knowledge gathering challenge, default to Google or other open source web-based searching, and as you can see from the bottom of this triangle, what that's doing is looking at 6.2 billion pages on the World Wide Web and hoping that something useful is going to crop up in your search results.
As we go higher up the pyramid, if you're looking just for peer-reviewed research in academic journals, you're still looking for a very very large volume and this is really just the volume in MEDLINE alone: 2500 papers being added every day. 
So the best place to start, and really the only place to start if you've only got three days, is to look for systematic reviews that have already gathered evidence from this primary part of the pyramid and assembled it and synthesized it. 
And I call that the peak of credible knowledge. You want to start right up here at the top of the triangle. Unfortunately, most people as I said start down here at the highest level of news, but the highest level of confidence in the information can be found at the top of the knowledge pyramid. 

Cochrane, of course, the Cochrane Collaboration really was the forerunner of systematic reviews or reviews of evidence and most people in medicine would know how to look at the Cochrane Database of systematic reviews to find evidence about the effectiveness of interventions. 
But there are many other platforms just like Cochrane covering lots of different areas faced by governments. So there is Health Systems Evidence, which looks really at the health systems or policy side of health, so how you implement and get health services to people that need them. 
There's the Cochrane Library as I mentioned.  In the social sciences and sustainable development goals there's social systems evidence, there's the Campbell Collaboration, and you can see that there are also useful platforms that assemble reviews of evidence in the areas of environment, the education area, and business. 
So there are lots of places that you can look and this really should be your first port of call when you're doing a three-day review - not the open internet. Quality really matters when you're looking at research evidence, so it's really important to mesh quality in the research that we're doing.  
Evidence is only useful if it's been well gathered and reviewed and systematic reviews have a recipe or an accepted methodology of steps that should be followed to summarize a body of research evidence. So-called narrative reviews which don't follow quite that rigorous a process but still bring together multiple research studies are still useful, but they should be interpreted with caution and you should always preference what you can find in a systematic review of evidence addressing your question. 
And just like the STARR Decision Tool, there is a tool called the AMSTAR Tool that steps you through the process of looking at a systematic review and evaluating it methodological quality. 
It's freely available, it's got training resources and guidance documents, it's in its second iteration, and has had a lot of validation work done on it. 
So there is a systematic way of looking at systematic reviews to evaluate their quality and what you want to do in your report back to government is you want to really start by summarizing what are the best quality systematic reviews saying about this particular topic. 
A lot of people say there's no systematic reviews in my area of expertise - "My area is very special, it's very specialized." Usually they find a review that is at least partially related or wholly related to the topic of interest in one of these platforms or by doing a database search.

But what do you do if you can't find reviews in your area? Well, you have to remember that published research is only one input into the knowledge game and the knowledge into policy game, and one of the limitations of systematic reviews is that they lag behind other sources of information. 
So by the time a systematic review is published the evidence within the review is generally one or two years old and obviously that means it can be out of date. 
So you need to be a bit creative if you can't find systematic reviews in a particular area. You may decide to go further down the knowledge pyramid and look for some high quality primary studies, perhaps a randomized controlled trial or a very high quality cohort study, but you may need to consider some other ways of gathering useful knowledge.
There are a lot of open sources of data that are available that can particularly in the COVID-19 area. Really the data on epidemiology and you know the emergence of various testing regimes is being used in real time. 
You can always pick up the phone and talk to an expert in a particular area. Perhaps you know of one through a university or a government agency who has published extensively in the area and can really shortcut you to the most useful piece of knowledge for your context. 
If there are outputs that are not published in peer-reviewed academic literature at all, reports from government agencies and other agencies- so-called grey literature. And there are in a lot of areas trusted organizations that assemble data and information like the International Panel for Climate Change for example, and they produce very useful reports that contain a lot of knowledge that can be mobilized. 

So there are the four principles. Get the question right. Look for review level research evidence. Remember that quality matters; it's not just finding evidence but knowing how useful that evidence is really means you have to understand the quality. 
And mobilize other sources of knowledge where necessary.  There's a couple of articles you might want to have a look at if you're really interested in this rapid review space.
One is "Evidence summaries: the evolution of a rapid review approach", which really talks through this process of doing reviews of reviews. 
Last year I wrote a little article about "Ten ways to optimize evidence-based policy," which talks about communicating with policymakers when you're in an academic space. 
And a few years ago now a seminal article on the principles of knowledge translation was written by Jeremy Grimshaw and  colleagues. And all of these articles are open access and freely available. 

So I hope that was useful. You can follow me on Twitter @BraggePeter, and why not check us out @MonashMSDI? Monash Sustainable Development Institute to find out more about the work we're doing. 

Thanks!
